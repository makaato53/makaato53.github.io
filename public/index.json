[{"content":"title: \u0026ldquo;Vectorization vs Loops: a mental model\u0026rdquo;\ndate: 2025-08-26\ntags: [\u0026ldquo;numpy\u0026rdquo;,\u0026ldquo;vectorization\u0026rdquo;,\u0026ldquo;python\u0026rdquo;]\ndraft: false\nWhy vectorization beats explicit loops; tiny benchmarks; common broadcasting gotchas.\n","permalink":"http://localhost:1313/posts/attention-vs-backprop/","summary":"\u003cp\u003etitle: \u0026ldquo;Vectorization vs Loops: a mental model\u0026rdquo;\u003c/p\u003e\n\u003cp\u003edate: 2025-08-26\u003c/p\u003e\n\u003cp\u003etags: [\u0026ldquo;numpy\u0026rdquo;,\u0026ldquo;vectorization\u0026rdquo;,\u0026ldquo;python\u0026rdquo;]\u003c/p\u003e\n\u003cp\u003edraft: false\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eWhy vectorization beats explicit loops; tiny benchmarks; common broadcasting gotchas.\u003c/p\u003e","title":""}]